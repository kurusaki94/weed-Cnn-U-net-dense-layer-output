{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proyecto_dl_2019.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxL_n2WkEBM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import h5py\n",
        "from keras.preprocessing.image import load_img,img_to_array\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPool2D, UpSampling2D, concatenate,Dropout,MaxPooling2D,Conv2DTranspose\n",
        "from keras.models import Model\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import os\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from sklearn import preprocessing as pp\n",
        "from keras import layers, activations\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import class_weight\n",
        "import cv2\n",
        "from skimage.util.shape import view_as_windows\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1jKCCxwECWl",
        "colab_type": "code",
        "outputId": "68d2b87a-fcd9-4e70-c541-ee4af3c16bf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyZG3tjEED0B",
        "colab_type": "code",
        "outputId": "604250cf-32b8-4414-dcd0-3ffe3ab338ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "os.chdir(\"/content/gdrive/My Drive/aula_sem_seg\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1_1.png\t\t\t\t\t Reference_Test.tif\n",
            " 1.png\t\t\t\t\t\t Reference_Train.tif\n",
            " 2_2.png\t\t\t\t\t semantic_segmentaion.ipynb\n",
            " 2.png\t\t\t\t\t\t'SemSeg (1).ipynb'\n",
            " ddpg_pendulum_exercise.ipynb\t\t\t'SemSeg (9).ipynb'\n",
            " example_seg.ipynb\t\t\t\t SemSeg.ipynb\n",
            " gt\t\t\t\t\t\t SemSeg.pptx\n",
            " images\t\t\t\t\t\t t1.png\n",
            " Images\t\t\t\t\t\t t2.png\n",
            " Image_Test.tif\t\t\t\t\t train_gt.png\n",
            " Image_Train.tif\t\t\t\t train.png\n",
            " img_1_32.png\t\t\t\t\t Transfer_Learning.ipynb\n",
            " img_reconstruct_128.png\t\t\t weed_1_32.png\n",
            " img_reconstruct_164.png\t\t\t weed_2_32.png\n",
            " img_reconstruct_256.png\t\t\t weed_3_32.png\n",
            " img_reconstruct_32.png\t\t\t\t weed_4_32.png\n",
            " img_reconstruct_remote_sensing_model1_256.png\t weed_5_32.png\n",
            " img_reconstruct_weed_1_264.png\t\t\t weed_j_32.png\n",
            " img_reconstruct_weed_164.png\t\t\t weed_r_32.png\n",
            " m1.png\t\t\t\t\t\t weed_result1_128.png\n",
            " m2.tif\t\t\t\t\t\t weed_result1_256.png\n",
            " model_a.h5\t\t\t\t\t weed_result_128.png\n",
            " model_a.json\t\t\t\t\t weed_result1_64.png\n",
            " model_b.h5\t\t\t\t\t weed_result_32.png\n",
            " model.json\t\t\t\t\t weed_result_64.png\n",
            " proyecto_dl_2019.ipynb\t\t\t\t weed_will.ipynb\n",
            " proyecto.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP1_0u5pFIva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_categorical_crossentropy(weights):\n",
        "   \n",
        "    if isinstance(weights,list) or isinstance(np.ndarray):\n",
        "        weights=K.variable(weights)\n",
        "\n",
        "    def loss(target,output,from_logits=False):\n",
        "        if not from_logits:\n",
        "            output /= tf.reduce_sum(output,\n",
        "                                    len(output.get_shape()) - 1,\n",
        "                                    True)\n",
        "            _epsilon = tf.convert_to_tensor(K.epsilon(), dtype=output.dtype.base_dtype)\n",
        "            output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n",
        "            weighted_losses = target * tf.log(output) * weights\n",
        "            return - tf.reduce_sum(weighted_losses,len(output.get_shape()) - 1)\n",
        "        else:\n",
        "            raise ValueError('error')\n",
        "    return loss\n",
        "def read_img_rgb(img_path):\n",
        "\timg = cv2.imread(img_path)\n",
        "\treturn img\n",
        "\n",
        "\n",
        "def read_img_gray(img_path):\n",
        "\timg = cv2.imread(img_path,0)\n",
        "\treturn img\n",
        "\n",
        "\n",
        "def show_result(acc, val_acc, loss, val_loss):\n",
        "    plt.rcParams['axes.facecolor']='white'\n",
        "    f, axarr = plt.subplots(1 , 2)\n",
        "    f.set_figwidth(10)\n",
        "\n",
        "    # Accuracy\n",
        "    axarr[0].plot(acc)\n",
        "    axarr[0].plot(val_acc)\n",
        "    axarr[0].set_title('model accuracy')\n",
        "    axarr[0].set_ylabel('accuracy')\n",
        "    axarr[0].set_xlabel('epoch')\n",
        "    axarr[0].legend(['train', 'valid'], loc='upper left')\n",
        "\n",
        "    # Loss\n",
        "    axarr[1].plot(loss)\n",
        "    axarr[1].plot(val_loss)\n",
        "    axarr[1].set_title('model loss')\n",
        "    axarr[1].set_ylabel('loss')\n",
        "    axarr[1].set_xlabel('epoch')\n",
        "    axarr[1].legend(['train', 'valid'], loc='upper left')\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "def extract_patches(img_array_path, img_reference_path, patches_size, stride):\n",
        "  \n",
        "    \"\"\"\n",
        "    Funtion to extract subimages patches \n",
        "    \"\"\"\n",
        "    img_array = read_img_rgb(img_array_path)\n",
        "    img_reference = read_img_gray(img_reference_path)\n",
        "    \n",
        "    rows = int(patches_size)\n",
        "    unique_class = np.unique(img_reference)\n",
        "    # convert from Gray to 0,1,2,3,4 classes \n",
        "    for i in range(len(unique_class)):\n",
        "        img_reference[img_reference==unique_class[i]] = i\n",
        "\n",
        "    # define the window_shape for patch extraction\n",
        "    window_shape_array = (rows, rows, img_array.shape[2])\n",
        "    window_shape_ref = (rows, rows)\n",
        "\n",
        "    # ectract patches\n",
        "    patches_array = np.array(view_as_windows(img_array, window_shape_array, step = stride))\n",
        "    patches_ref = np.array(view_as_windows(img_reference, window_shape_ref, step = stride))\n",
        "   \n",
        "    k1,k2,p,row,col,depth = patches_array.shape\n",
        "\n",
        "    patches_array = patches_array.reshape(k1*k2,row,col,depth)   \n",
        "    patches_ref = patches_ref.reshape(k1*k2,row,col) \n",
        "\n",
        "    return patches_array, patches_ref\n",
        "  \n",
        "\n",
        "def data_augmentation(data, labels):\n",
        "    \"\"\"\n",
        "    Funtion for data augmentation, for each patch apply rotation (90, 180, 270)\n",
        "    and flip horizontal and vertical\n",
        "    \"\"\"\n",
        "    augmented_data = data\n",
        "    augmented_labels = labels\n",
        "\n",
        "\n",
        "    cont_transf = 0\n",
        "    for i in range(6):                \n",
        "        augmented_data_temp = data\n",
        "        augmented_label_temp = labels\n",
        "        \n",
        "        if cont_transf == 0:\n",
        "            augmented_data_temp = np.rot90(augmented_data_temp,1,(1,2))\n",
        "            augmented_label_temp = np.rot90(augmented_label_temp,1,(1,2))\n",
        "        \n",
        "        elif cont_transf == 1:\n",
        "            augmented_data_temp = np.rot90(augmented_data_temp,2,(1,2))\n",
        "            augmented_label_temp = np.rot90(augmented_label_temp,2,(1,2))\n",
        "\n",
        "        elif cont_transf == 2:\n",
        "            augmented_data_temp = np.flip(augmented_data_temp,1)\n",
        "            augmented_label_temp = np.flip(augmented_label_temp,1)\n",
        "            \n",
        "        elif cont_transf == 3:\n",
        "            augmented_data_temp = np.flip(augmented_data_temp,2)\n",
        "            augmented_label_temp = np.flip(augmented_label_temp,2)\n",
        "        \n",
        "        elif cont_transf == 4:\n",
        "            augmented_data_temp = np.rot90(augmented_data_temp,3,(1,2))\n",
        "            augmented_label_temp = np.rot90(augmented_label_temp,3,(1,2))\n",
        "            \n",
        "        elif cont_transf == 5:\n",
        "            augmented_data_temp = augmented_data_temp\n",
        "            augmented_label_temp = augmented_label_temp\n",
        "            \n",
        "           \n",
        "        augmented_data = np.vstack((augmented_data,augmented_data_temp))\n",
        "        augmented_labels = np.vstack((augmented_labels,augmented_label_temp))\n",
        "\n",
        "    idx = np.random.permutation(augmented_data.shape[0])\n",
        "    out_data = augmented_data[idx]\n",
        "    out_labels = augmented_labels[idx]\n",
        "\n",
        "    return out_data, out_labels\n",
        "  \n",
        "  \n",
        "def unblockshaped(blocks, h, w):\n",
        "    \"\"\"\n",
        "    Funtion to mosaicking back the patches \n",
        "    \"\"\"\n",
        "    n, nrows, ncols = blocks.shape\n",
        "    bpc = w//ncols\n",
        "    bpr = h//nrows\n",
        "\n",
        "    reconstructed = np.zeros((h,w))\n",
        "    t = 0\n",
        "    for i in range(bpr):\n",
        "        for j in range(bpc):\n",
        "            reconstructed[i*nrows:i*nrows+nrows,j*ncols:j*ncols+ncols] = blocks[t]\n",
        "            t = t+1\n",
        "    return reconstructed\n",
        "  \n",
        "def gray2rgb(image):\n",
        "    \"\"\"\n",
        "    Funtion to convert classes values from 0,1,3,4 to rgb values\n",
        "    \"\"\"\n",
        "    row,col = image.shape\n",
        "    image = image.reshape((row*col))\n",
        "    rgb_output = np.zeros((row*col, 3))\n",
        "    rgb_map = [[0,0,255],[0,255,0],[0,255,255],[255,255,0],[255,255,255]]\n",
        "    for j in np.unique(image):\n",
        "        rgb_output[image==j] = np.array(rgb_map[j])\n",
        "    \n",
        "    rgb_output = rgb_output.reshape((row,col,3))  \n",
        "    rgb_output = cv2.cvtColor(rgb_output.astype('uint8'),cv2.COLOR_BGR2RGB)\n",
        "    return rgb_output\n",
        "  \n",
        "def compute_metrics(true_labels, predicted_labels):\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    f1score = 100*f1_score(true_labels, predicted_labels, average=None)\n",
        "    recall = 100*recall_score(true_labels, predicted_labels, average=None)\n",
        "    prescision = 100*precision_score(true_labels, predicted_labels, average=None)\n",
        "    return accuracy, f1score, recall, prescision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW1s5XzvHs_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EncDec (nClasses , optimizer=None , input_width=32 , input_height=32 , nChannels=3 ): \n",
        "  ########################################\n",
        "  ##            Code here               ##\n",
        "  ##  Change network architecture       ##\n",
        "  ########################################    \n",
        "  inputs = Input((input_height, input_width, nChannels))\n",
        "  c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (inputs)\n",
        "  c1 = Dropout(0.1) (c1)\n",
        "  c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "  p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "  c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "  c2 = Dropout(0.1) (c2)\n",
        "  c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "  p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "  c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "  c3 = Dropout(0.2) (c3)\n",
        "  c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "  p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "  c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "  c4 = Dropout(0.2) (c4)\n",
        "  c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "  p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "  c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "  c5 = Dropout(0.3) (c5)\n",
        "  c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "  u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "  u6 = concatenate([u6, c4])\n",
        "  c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "  c6 = Dropout(0.2) (c6)\n",
        "  c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "  u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "  u7 = concatenate([u7, c3])\n",
        "  c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "  c7 = Dropout(0.2) (c7)\n",
        "  c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "  u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "  u8 = concatenate([u8, c2])\n",
        "  c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "  c8 = Dropout(0.1) (c8)\n",
        "  c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "  u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "  u9 = concatenate([u9, c1], axis=3)\n",
        "  c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "  c9 = Dropout(0.1) (c9)\n",
        "  c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "  \n",
        "  outputs = Conv2D(64, (1, 1), activation='relu') (c9)\n",
        "\n",
        "  outputs = Conv2D(3, (1, 1), activation='softmax') (outputs)\n",
        " \n",
        "\n",
        "  model = Model(inputs, outputs)\n",
        "  #custom_loss = weights_categorical_crossentropy(categorical_weight)\n",
        "\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer , metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDFaUWJNEVbv",
        "colab_type": "text"
      },
      "source": [
        "#train and test\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8OCuqQtEFpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Train_Test(net, train_array, train_ref, test_array, test_ref, batch_size, epochs):\n",
        "    \n",
        "    # apply data augmentation\n",
        "    train_array,train_ref = data_augmentation(train_array,train_ref)\n",
        "    \n",
        "    # one_hot classes\n",
        "    num_classes = len(np.unique(train_ref))\n",
        "    imgs_mask_cat = train_ref.reshape(train_ref.shape[0]*train_ref.shape[1]*train_ref.shape[2])\n",
        "    imgs_mask_cat = keras.utils.to_categorical(imgs_mask_cat, num_classes)\n",
        "    train_ref = imgs_mask_cat.reshape(train_ref.shape[0],train_ref.shape[1],train_ref.shape[2],num_classes)\n",
        "    imgs_mask_cat = []\n",
        "    \n",
        "    print('Start the training')\n",
        "    patch_size = train_ref.shape[1]\n",
        "\n",
        "    # train\n",
        "    history = net.fit(train_array, train_ref,\n",
        "                      batch_size = batch_size,\n",
        "                      epochs = epochs,\n",
        "                      verbose = 1,\n",
        "                      shuffle = True)\n",
        "\n",
        "\n",
        "    train_array, train_ref = 0,0 \n",
        "    # clear memory \n",
        "    gc.collect() \n",
        "\n",
        "    # one_hot classes\n",
        "    imgs_mask_cat = test_ref.reshape(test_ref.shape[0]*test_ref.shape[1]*test_ref.shape[2])\n",
        "    imgs_mask_cat = keras.utils.to_categorical(imgs_mask_cat, num_classes)\n",
        "    test_encoding = imgs_mask_cat.reshape(test_ref.shape[0],test_ref.shape[1],test_ref.shape[2],num_classes)\n",
        "    imgs_mask_cat = []\n",
        "\n",
        "    # evaluate in test\n",
        "    score = net.evaluate(test_array, test_encoding, verbose=1)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1]*100)\n",
        "    \n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coAuzUZxQ4Y3",
        "colab_type": "text"
      },
      "source": [
        "#Main \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieOGYqIzGW5d",
        "colab_type": "code",
        "outputId": "ece22d7f-dc44-4577-e15a-5eca5fa6e0cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1650
        }
      },
      "source": [
        "if __name__=='__main__':\n",
        "    \n",
        "  # patches size\n",
        "  ##### change here #####\n",
        "  patches_size = 64\n",
        "\n",
        "  # path for test and train data\n",
        "  train_array_path = './train.png'\n",
        "  train_reference_path = './train_gt.png'    \n",
        "  test_array_path = './images/2.png'\n",
        "  test_reference_path = './gt/2.png'\n",
        "\n",
        "\n",
        "  # non overlapping patches with stride = patches_size\n",
        "  stride = int(0.5*patches_size)\n",
        "  weed_pixel = 0\n",
        "  crop_pixel = 0\n",
        "  background_pixel = 0\n",
        "  # extract training pacthes \n",
        "  train_array,train_ref = extract_patches(train_array_path,\n",
        "                                          train_reference_path, \n",
        "                                          patches_size, stride)\n",
        "  \n",
        "  print(train_ref[1].shape)\n",
        "  numb_patch, row, col, bands = train_array.shape\n",
        "\n",
        "  # extract test pacthes \n",
        "  test_array, test_ref = extract_patches(test_array_path,\n",
        "                                         test_reference_path,\n",
        "                                         patches_size, patches_size)\n",
        "\n",
        "  # standarize features removing the mean and scaling to unit variance\n",
        "  row,image_size,image_size,bands= train_array.shape            \n",
        "  train_array = train_array.reshape(row,image_size*image_size*bands)            \n",
        "  scaler = pp.StandardScaler().fit(train_array)            \n",
        "  train_array = scaler.transform(train_array)\n",
        "  train_array = train_array.reshape(row,image_size,image_size,bands)\n",
        "\n",
        "  row,image_size,image_size,bands= test_array.shape            \n",
        "  test_array = test_array.reshape(row,image_size*image_size*bands)                   \n",
        "  test_array = scaler.transform(test_array)\n",
        "  test_array = test_array.reshape(row,image_size,image_size,bands)\n",
        "\n",
        "  # define model \n",
        "  optimazer = keras.optimizers.Adamax(lr = 1e-3)\n",
        "  classes = 3      \n",
        "  train_ref_forclassw = train_ref.reshape(train_ref.shape[0]*image_size*image_size)\n",
        "  net = EncDec(classes, optimizer=optimazer, input_width=patches_size, input_height=patches_size, nChannels=bands)\n",
        "  net.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 64)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 64, 64, 16)   448         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 64, 64, 16)   0           conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 64, 64, 16)   2320        dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 16)   0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 32, 32, 32)   4640        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 32, 32, 32)   0           conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 32, 32, 32)   9248        dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 16, 16, 32)   0           conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 64)   18496       max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 16, 16, 64)   0           conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 64)   36928       dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 64)     0           conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 8, 8, 128)    73856       max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 8, 8, 128)    0           conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 8, 8, 128)    147584      dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 4, 4, 128)    0           conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 256)    295168      max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 4, 4, 256)    0           conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 256)    590080      dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_9 (Conv2DTrans (None, 8, 8, 128)    131200      conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 8, 8, 256)    0           conv2d_transpose_9[0][0]         \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 8, 8, 128)    295040      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 8, 8, 128)    0           conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 8, 8, 128)    147584      dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_10 (Conv2DTran (None, 16, 16, 64)   32832       conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 16, 16, 128)  0           conv2d_transpose_10[0][0]        \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 64)   73792       concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 16, 16, 64)   0           conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 64)   36928       dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_11 (Conv2DTran (None, 32, 32, 32)   8224        conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 64)   0           conv2d_transpose_11[0][0]        \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 32, 32, 32)   18464       concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 32, 32, 32)   0           conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 32, 32, 32)   9248        dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_12 (Conv2DTran (None, 64, 64, 16)   2064        conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 64, 64, 32)   0           conv2d_transpose_12[0][0]        \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 64, 64, 16)   4624        concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 64, 64, 16)   0           conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 64, 64, 16)   2320        dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 64, 64, 64)   1088        conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 64, 64, 3)    195         conv2d_59[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,942,371\n",
            "Trainable params: 1,942,371\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB06jYhj12m8",
        "colab_type": "code",
        "outputId": "20b349d1-1954-4fce-f302-cf20f5541258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "\n",
        "  # Train and Test\n",
        "  #Call the train_test function\n",
        "  model = Train_Test(net, train_array, train_ref, test_array, test_ref, batch_size=80, epochs=8)\n",
        "  train_array, train_ref = 0,0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start the training\n",
            "Epoch 1/8\n",
            "16128/16128 [==============================] - 16s 1ms/step - loss: 0.1894 - acc: 0.9208\n",
            "Epoch 2/8\n",
            "16128/16128 [==============================] - 15s 937us/step - loss: 0.1039 - acc: 0.9611\n",
            "Epoch 3/8\n",
            "16128/16128 [==============================] - 15s 930us/step - loss: 0.0873 - acc: 0.9676\n",
            "Epoch 4/8\n",
            "16128/16128 [==============================] - 15s 920us/step - loss: 0.0805 - acc: 0.9695\n",
            "Epoch 5/8\n",
            "16128/16128 [==============================] - 15s 917us/step - loss: 0.0755 - acc: 0.9709\n",
            "Epoch 6/8\n",
            "16128/16128 [==============================] - 15s 912us/step - loss: 0.0721 - acc: 0.9721\n",
            "Epoch 7/8\n",
            "16128/16128 [==============================] - 15s 913us/step - loss: 0.0678 - acc: 0.9735\n",
            "Epoch 8/8\n",
            "16128/16128 [==============================] - 15s 915us/step - loss: 0.0645 - acc: 0.9745\n",
            "576/576 [==============================] - 1s 903us/step\n",
            "Test loss: 0.17517797317769793\n",
            "Test accuracy: 94.48835584852431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYEiLOCBaAqu",
        "colab_type": "code",
        "outputId": "383932f0-1977-4356-9f04-cb385578a7c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model_a.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_a.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "#json_file = open('model_b.json', 'r')\n",
        "#loaded_model_json = json_file.read()\n",
        "#json_file.close()\n",
        "#loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "#loaded_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer , metrics=['accuracy'])\n",
        "# load weights into new model\n",
        "#loaded_model.load_weights(\"model_b.h5\")\n",
        "#print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgffVFiJQ_33",
        "colab_type": "code",
        "outputId": "30d2c801-5228-4625-ff64-98ea8523a0d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "  # get test predictions\n",
        "  predict_test = net.predict(test_array, verbose=1) \n",
        "  predict_test = predict_test.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "576/576 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Yw7SAyJimC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "  # mosaicking back\n",
        "  dim1 = (1584//patches_size)*patches_size\n",
        "  dim2 = (1584//patches_size)*patches_size\n",
        "  DIM = [dim1,dim2]\n",
        "  img_reconstruct = unblockshaped(predict_test, DIM[0], DIM[1])\n",
        "  img_reconstruct = img_reconstruct.astype('uint8')\n",
        "\n",
        "  img_ref = unblockshaped(test_ref, DIM[0], DIM[1])\n",
        "  img_ref = img_ref.astype('uint8')\n",
        "\n",
        "  # save label image\n",
        "  save_rgb = gray2rgb(img_reconstruct)\n",
        "  cv2.imwrite('./weed_result1_' + str(patches_size) + '.png',save_rgb) \n",
        "\n",
        "  img_reconstruct = img_reconstruct.reshape(DIM[0]*DIM[1])\n",
        "  img_ref = img_ref.reshape(DIM[0]*DIM[1])\n",
        "  \n",
        "  # get metrics\n",
        "  accuracy, f1score, recall, precision = compute_metrics(img_ref, img_reconstruct)\n",
        "  \n",
        "  print('Test accuracy:', accuracy)\n",
        "  print('Test f1score:', f1score)\n",
        "  print('Test recall:', recall)\n",
        "  print('Test prescision:', precision) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOUXQMBrTAEA",
        "colab_type": "code",
        "outputId": "25c33b19-e963-48c9-a773-7690db2693ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "save_rgb[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[255,   0,   0],\n",
              "       [255,   0,   0],\n",
              "       [255,   0,   0],\n",
              "       ...,\n",
              "       [255,   0,   0],\n",
              "       [255,   0,   0],\n",
              "       [255,   0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BqLi9Yseb4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)]\n",
        "plt.figure(figsize=(20,16))\n",
        "plt.subplot(2,3,1)\n",
        "plt.title(\"result\")\n",
        "plt.imshow(save_rgb)\n",
        "\n",
        "img1 = load_img(test_array_path)\n",
        "img2=load_img(test_reference_path)\n",
        "plt.subplot(2,3,2)\n",
        "plt.title(\"label\")\n",
        "plt.imshow(img2)\n",
        "\n",
        "\n",
        "plt.subplot(2,3,3)\n",
        "plt.title(\"image\")\n",
        "plt.imshow(img1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umNEVFqzhNpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rr=img_to_array(img1)\n",
        "img_rr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGhcCqltRRv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "color=save_rgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoigQQlUiQJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}