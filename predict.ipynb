{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize,rotate\n",
    "from skimage.measure import find_contours\n",
    "from skimage.util import invert\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "from keras.optimizers import SGD, Adam\n",
    "import keras.backend as K\n",
    "import keras\n",
    "from keras import layers, activations\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.engine.topology import Layer\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "from IPython.display import Image\n",
    "import tensorflow as tf\n",
    "import Augmentor\n",
    "import yaml\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "\n",
    "####path\n",
    "images_names_train=os.listdir('dataset-5.0/train/image/')\n",
    "mask_names_train=os.listdir('dataset-5.0/train/annotation/')\n",
    "############################################################\n",
    "images_names_test=os.listdir('dataset-4.0/test/image/')\n",
    "mask_names_test=os.listdir('dataset-4.0/test/annotation/')\n",
    "####dataset construct\n",
    "for i in images_names_train:\n",
    "    x_path = os.path.join('dataset-5.0/train/image/'+ i) \n",
    "    img = load_img(x_path,target_size=(128,128))\n",
    "    img = img_to_array(img)/255\n",
    "    train_x.append(img)\n",
    "for j in mask_names_train:\n",
    "    y_path = os.path.join('dataset-5.0/train/annotation/'+ j) \n",
    "    img = load_img(y_path,target_size=(128,128))\n",
    "    img = img_to_array(img)/255\n",
    "    \n",
    "    weed = img[:,:,0]\n",
    "    crop = img[:,:,1]\n",
    "\n",
    "    y = np.zeros((128,128,3))\n",
    "    y[:,:, 0] = weed\n",
    "    y[:, :, 1] = crop\n",
    "    \n",
    "    back = img.copy()\n",
    "    back = np.all(img == [0, 0, 0],axis=-1)*1\n",
    "    y[:,:, 2] = back\n",
    "    \n",
    "    y = np.reshape(y,(128*128,3))\n",
    "    \n",
    "    train_y.append(y)\n",
    "############################################################\n",
    "for i in images_names_test:\n",
    "    x_path = os.path.join('dataset-4.0/test/image/'+ i) \n",
    "    img = load_img(x_path,target_size=(128,128))\n",
    "    img = img_to_array(img)/255\n",
    "    test_x.append(img)\n",
    "for j in mask_names_test:\n",
    "    y_path = os.path.join('dataset-4.0/test/annotation/'+ j) \n",
    "    img = load_img(y_path,target_size=(128,128))\n",
    "    img = img_to_array(img)/255\n",
    "    \n",
    "    weed = img[:,:,0]\n",
    "    crop = img[:,:,1]\n",
    "\n",
    "    y = np.zeros((128,128,3))\n",
    "    y[:,:, 0] = weed\n",
    "    y[:, :, 1] = crop\n",
    "    \n",
    "    back = img.copy()\n",
    "    back = np.all(img == [0, 0, 0],axis=-1)*1\n",
    "    y[:,:, 2] = back\n",
    "    \n",
    "    y = np.reshape(y,(128*128,3))\n",
    "    \n",
    "    test_y.append(y)\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "#analise pixel lvl for classess\n",
    "weed_pixel = 0\n",
    "crop_pixel = 0\n",
    "background_pixel = 0\n",
    "for j in mask_names_train:\n",
    "    y_path = os.path.join('dataset-4.0/train/annotation/'+ j) \n",
    "    img = load_img(y_path,target_size=(128,128))\n",
    "    img = img_to_array(img)/255\n",
    "    weed = img[:,:,0]\n",
    "    _pixel = np.sum(weed.flatten())\n",
    "    weed_pixel += _pixel \n",
    "    crop = img[:,:,1]\n",
    "    _pixel = np.sum(crop.flatten())\n",
    "    crop_pixel += _pixel\n",
    "\n",
    "    back = img.copy()\n",
    "    back = np.all(img == [0, 0, 0],axis=-1) * 1\n",
    "    _pixel = np.sum(back.flatten())\n",
    "    background_pixel += _pixel\n",
    "\n",
    "categorical_weight = [background_pixel/weed_pixel, background_pixel/crop_pixel, 1]\n",
    "def weights_categorical_crossentropy(weights):\n",
    "   \n",
    "    if isinstance(weights,list) or isinstance(np.ndarray):\n",
    "        weights=K.variable(weights)\n",
    "\n",
    "    def loss(target,output,from_logits=False):\n",
    "        if not from_logits:\n",
    "            output /= tf.reduce_sum(output,\n",
    "                                    len(output.get_shape()) - 1,\n",
    "                                    True)\n",
    "            _epsilon = tf.convert_to_tensor(K.epsilon(), dtype=output.dtype.base_dtype)\n",
    "            output = tf.clip_by_value(output, _epsilon, 1. - _epsilon)\n",
    "            weighted_losses = target * tf.log(output) * weights\n",
    "            return - tf.reduce_sum(weighted_losses,len(output.get_shape()) - 1)\n",
    "        else:\n",
    "            raise ValueError('error')\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "def precision(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    return K.mean(p)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    return K.mean(r)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_file = open('model_b.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "loaded_model.compile(loss=custom_loss,optimizer=adam,metrics=['accuracy',f1,precision,recall,mean_iou])\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_b.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
